{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5nrhIpgLpa9aZpBPhT3HH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Информационный поиск\n","Скачиваем классический набор данных -- набор текстов об аэронавтике CRANFIELD\n","\n","* `wget <option> <url>` - utility for downloading network data\n","* `tar <option> <archive_path>` - utility for creating and extracting files from archives"],"metadata":{"id":"0EhBFFB0u8fA"}},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EajLRKGUucYA","executionInfo":{"status":"ok","timestamp":1682373378924,"user_tz":-180,"elapsed":1627,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"c5393762-71c7-4499-c931-2f42ce71f68b"},"outputs":[{"output_type":"stream","name":"stdout","text":["cran.all.1400\n","cran.qry\n","cranqrel\n","cranqrel.readme\n"]}],"source":["! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n","! tar -xvf cran.tar.gz\n","! rm cran.tar.gz*"]},{"cell_type":"markdown","source":["Берём только сами запросы (это будут наши документы)"],"metadata":{"id":"59EqHCBxvJyv"}},{"cell_type":"code","source":["! grep -v \"^\\.\" cran.qry > just.qry\n","! head -3 just.qry"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzRokfoMvMYe","executionInfo":{"status":"ok","timestamp":1682373379252,"user_tz":-180,"elapsed":6,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"5026f8ea-de4f-4184-bd18-ca70528b66c2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["what similarity laws must be obeyed when constructing aeroelastic models\r\n","of heated high speed aircraft .\r\n","what are the structural and aeroelastic problems associated with flight\r\n"]}]},{"cell_type":"markdown","source":["Объединяем многострочные в один"],"metadata":{"id":"VxDG6CS7xDde"}},{"cell_type":"code","source":["raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n","query_data = [\"\"]\n","\n","for query_part in raw_query_data:\n","  query_data[-1] += query_part + \" \"\n","  if query_part.endswith(\".\"):\n","    query_data.append(\"\")\n","\n","query_data[:2] #Выведем пару документов для примера"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyy_xjvExC-_","executionInfo":{"status":"ok","timestamp":1682373380180,"user_tz":-180,"elapsed":3,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"107c71a1-2b43-49ee-c53b-fe3ceb59536d"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . ',\n"," 'what are the structural and aeroelastic problems associated with flight of high speed aircraft . ']"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Составим запросы к нашим документам"],"metadata":{"id":"v_yPYL22xHae"}},{"cell_type":"code","source":["QUERIES = ['theory of bending', 'aeroelastic effects']"],"metadata":{"id":"LWhL6AabxLmo","executionInfo":{"status":"ok","timestamp":1682373382446,"user_tz":-180,"elapsed":262,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Boolean retrieval\n","\n","Представим каждый документ как \"битовую маску\": вектор размером со словарь, в котором на каждой позиции единица, если в документе есть соответствующий терм, и ноль, если терма нет.\n","\n","Воспользуемся объектом [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"],"metadata":{"id":"5ykLqn6xxWNX"}},{"cell_type":"code","source":["# в разных версиях ответы могут отличаться, поэтому важно иметь одну и ту же\n","! pip install -q scikit-learn==0.22.2.post1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9l4w13axcIv","executionInfo":{"status":"ok","timestamp":1682373388772,"user_tz":-180,"elapsed":5121,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"d246dea9-1558-44be-a682-cb4b453e435c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/6.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/6.9 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for scikit-learn (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/req_command.py\", line 241, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/commands/install.py\", line 463, in run\n","    _, build_failures = build(\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/wheel_builder.py\", line 347, in build\n","    wheel_file = _build_one(\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/wheel_builder.py\", line 221, in _build_one\n","    wheel_path = _build_one_inside_env(\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/wheel_builder.py\", line 268, in _build_one_inside_env\n","    wheel_path = build_wheel_legacy(\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n","    output = call_subprocess(\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n","    line: str = proc.stdout.readline()\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/base_command.py\", line 214, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/base_command.py\", line 198, in exc_logging_wrapper\n","    logger.debug(\"Exception information:\", exc_info=True)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 1434, in debug\n","    self._log(DEBUG, msg, args, **kwargs)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 1589, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 1599, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 1661, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 952, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.9/logging/handlers.py\", line 75, in emit\n","    logging.FileHandler.emit(self, record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 1187, in emit\n","    StreamHandler.emit(self, record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 1083, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 927, in format\n","    return fmt.format(record)\n","  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n","    formatted = super().format(record)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 671, in format\n","    record.exc_text = self.formatException(record.exc_info)\n","  File \"/usr/lib/python3.9/logging/__init__.py\", line 621, in formatException\n","    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n","  File \"/usr/lib/python3.9/traceback.py\", line 103, in print_exception\n","    for line in TracebackException(\n","  File \"/usr/lib/python3.9/traceback.py\", line 517, in __init__\n","    self.stack = StackSummary.extract(\n","  File \"/usr/lib/python3.9/traceback.py\", line 366, in extract\n","    f.line\n","  File \"/usr/lib/python3.9/traceback.py\", line 288, in line\n","    self._line = linecache.getline(self.filename, self.lineno).strip()\n","  File \"/usr/lib/python3.9/linecache.py\", line 30, in getline\n","    lines = getlines(filename, module_globals)\n","  File \"/usr/lib/python3.9/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","  File \"/usr/lib/python3.9/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","  File \"/usr/lib/python3.9/tokenize.py\", line 394, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","  File \"/usr/lib/python3.9/tokenize.py\", line 363, in detect_encoding\n","    first = read_or_stop()\n","  File \"/usr/lib/python3.9/tokenize.py\", line 321, in read_or_stop\n","    return readline()\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["from  sklearn.feature_extraction.text import CountVectorizer\n","\n","encoder = CountVectorizer(binary=True)\n","encoded_data = encoder.fit_transform(query_data)\n","encoded_queries = encoder.transform(QUERIES)\n","list(encoder.vocabulary_)[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mA6e5EW8xd2O","executionInfo":{"status":"ok","timestamp":1682373390299,"user_tz":-180,"elapsed":1533,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"ae641728-d9f7-4c24-a7e8-c2834ea80466"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['what', 'similarity', 'laws']"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["Посмотрим на представление первого предложения"],"metadata":{"id":"Y2hCMFzFxgk3"}},{"cell_type":"code","source":["id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n","non_zero_values_ids = encoded_data[0].nonzero()[1]\n","\n","terms = [id2term[idx] for idx in non_zero_values_ids]\n","terms"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kloAl8TxhJI","executionInfo":{"status":"ok","timestamp":1682373394365,"user_tz":-180,"elapsed":4,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"38ef736f-911f-4b40-e601-41937b71272f"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['what',\n"," 'similarity',\n"," 'laws',\n"," 'must',\n"," 'be',\n"," 'obeyed',\n"," 'when',\n"," 'constructing',\n"," 'aeroelastic',\n"," 'models',\n"," 'of',\n"," 'heated',\n"," 'high',\n"," 'speed',\n"," 'aircraft']"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["Всё так."],"metadata":{"id":"dontsJ9DxjGA"}},{"cell_type":"markdown","source":["## Задание 0\n","\n","Теперь для каждого из данных запросов QUERIES найдём ближайший для него документ из query_data по сходству Жаккара. Есть более эффективные способы это сделать, но вам требуется реализовать расстояние Жаккара и далее применить его к нашим данным."],"metadata":{"id":"YK0W6jutxkP-"}},{"cell_type":"code","source":["import numpy as np \n","\n","def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n","  \"\"\"\n","    Сходство или коэффициент Жаккара: отношение мощности пересечения\n","    к мощности объединения\n","  \"\"\"\n","\n","  jaccard_dist = sum(vector_a & vector_b) / sum(vector_a | vector_b)\n","  return jaccard_dist\n","\n","#Проверка, что функция работает правильно\n","assert jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4"],"metadata":{"id":"NJqdhxn7xqSW","executionInfo":{"status":"ok","timestamp":1682373397303,"user_tz":-180,"elapsed":266,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Здесь документы представлены так же, как строки в матрице термов-документов. Каждая ячейка вектора отвечает за наличие/отсутствие конкретного элемента (например, слова-терма, когда у нас в словаре всего 5 слов). В первом случае их три, во втором — четыре. Объединение — все пять возможных элементов. Пересечение — два. Отсюда и 0.4."],"metadata":{"id":"fbtwkyWSxsMm"}},{"cell_type":"markdown","source":["## Задание 1\n","\n","Теперь с помощью кода ниже вычислите для каждого запроса самые близкие документы."],"metadata":{"id":"DG5Gymbmxt2u"}},{"cell_type":"code","source":["for q_id, query in enumerate(encoded_queries):\n","  # приводим к нужному типу\n","  query = query.todense().A1\n","  docs = [doc.todense().A1 for doc in encoded_data]\n","  # вычисляем коэфф. Жаккара\n","  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n","  # сортируем по нему\n","  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n","  \n","  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n","  # выводим по 3 наиболее близких документа для каждого запроса\n","  for closest_id, _, sim in closest[:3]:\n","    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"],"metadata":{"id":"kFUim3RWxyHW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682373400682,"user_tz":-180,"elapsed":1489,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"3fdfda58-5a2a-4e97-df8c-b9f6009168e4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Q: theory of bending\n","FOUND:\n","    42\t0.20\twhat are the details of the rigorous kinetic theory of gases . \n","    43\t0.20\t(chapman-enskog theory) . \n","    146\t0.19\tdoes a membrane theory exist by which the behaviour of pressurized membrane cylinders in bending can be predicted . \n","Q: aeroelastic effects\n","FOUND:\n","    196\t0.14\tthe problem of similarity for representative investigation of aeroelastic effects in a flow with the absence of heating effects . \n","    204\t0.12\tdo viscous effects seriously modify pressure distributions . \n","    114\t0.12\tis the problem of similarity for representative investigations of aeroelastic effects in heated flow as intractable as previous investigations imply . \n"]}]},{"cell_type":"markdown","source":["Видим, что кое-где просачиваются тексты, которых с запросами объединяют малозначительные термы, но при этом коэффициент Жаккара -- наша функция ранжирования! -- высок."],"metadata":{"id":"aCruQYR9x1Lv"}},{"cell_type":"markdown","source":["## VSM\n","\n","Попробуем теперь сделать то же, но с tf-idf и косинусным расстоянием. Мы сделаем всё опять \"руками\", но \"в реальной жизни\" лучше использоватьесть эффективные реализации cosine distance, например, из библиотеки scipy."],"metadata":{"id":"pnL3-Xw7x19-"}},{"cell_type":"code","source":["from  sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Совет: обязательно разберитесь с тем, какие возможности\n","# предоставляет tf-idf vectorizer, какие параметры за что отвечают\n","\n","tfidf_encoder = TfidfVectorizer()\n","tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n","tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n","\n","list(tfidf_encoder.vocabulary_)[:3]"],"metadata":{"id":"WfQaST5Yx5ae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682373548897,"user_tz":-180,"elapsed":392,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"ff4217f9-9cb1-440d-ebc5-e1412f1dea4a"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['what', 'similarity', 'laws']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## Задание 2\n","\n","Реализовать косинусное расстояние\n","\n","Скалярным произведением двух векторов называется число, равное произведению длин этих векторов на косинус угла между ними.\n","\n","Норма вектора - это длина вектора."],"metadata":{"id":"AlQje-ugx8nO"}},{"cell_type":"code","source":["import numpy as np \n","\n","def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n","  \"\"\"\n","    Косинусное расстояние: единица минус отношение скалярного произведения\n","    на произведение L2-норм (подсказка: в numpy такие нормы есть)\n","  \"\"\"\n","\n","  return 1 - np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n","\n","#Проверка, что функция работает правильно\n","assert cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])) == 0.5"],"metadata":{"id":"kqvsu_U_yAMu","executionInfo":{"status":"ok","timestamp":1682374821726,"user_tz":-180,"elapsed":280,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Теперь вычислим ближайшие по косинусному расстоянию между векторными представлениями документов и запросов"],"metadata":{"id":"UNFESjfTyCGe"}},{"cell_type":"code","source":["for q_id, query in enumerate(tfidf_encoded_queries):\n","  \n","  # приводим к нужному типу\n","  query = query.todense().A1\n","  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n","  # Косинусное расстояние\n","  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n","                       for doc_id, doc in enumerate(docs)]\n","  # сортируем по нему\n","  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n","  \n","  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n","  \n","  for closest_id, _, sim in closest[:3]:\n","    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"],"metadata":{"id":"T1qfwoh9yDke","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682374825971,"user_tz":-180,"elapsed":270,"user":{"displayName":"Anatolii Briushinin","userId":"13366799926111712317"}},"outputId":"1956bef5-22fa-4164-cc85-a843f21ee3b9"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Q: theory of bending\n","FOUND:\n","    145\t0.65\twhat are the best experimental data and classical small deflection theory analyses available for pressurized cylinders in bending . \n","    146\t0.66\tdoes a membrane theory exist by which the behaviour of pressurized membrane cylinders in bending can be predicted . \n","    111\t0.66\thas the solution of the clamped plate problem,  in the classical theory of bending,  been reduced to two successive membrane boundary value problems . \n","Q: aeroelastic effects\n","FOUND:\n","    196\t0.51\tthe problem of similarity for representative investigation of aeroelastic effects in a flow with the absence of heating effects . \n","    114\t0.70\tis the problem of similarity for representative investigations of aeroelastic effects in heated flow as intractable as previous investigations imply . \n","    1\t0.74\twhat are the structural and aeroelastic problems associated with flight of high speed aircraft . \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-b0763db6b950>:9: RuntimeWarning: invalid value encountered in double_scalars\n","  return 1 - np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n"]}]}]}