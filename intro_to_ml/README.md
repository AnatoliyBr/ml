## 2. Введение в МО (Python)

## Содержание
* [Введение в машинное обучение](#введение-в-машинное-обучение)
* [Регрессия](#регрессия)
* Задача классификации
    * [k-NN](#классификатор-k-nn)
    * Наивный байесовский классификатор
    * Логистическая регрессия
* Кластеризация

## Введение в машинное обучение

### Определения
* Машинное обучение (МО) - статистическое обучение
* Предикторы (признаки) - входные данные (независимые переменные)
* Отклики - выходные данные (зависимые переменные)
* Тренировочный набор данных - для обучения модели
* Тестовый набор данных - для проверки эффективности ("правильности") модели

### Диаграмма терминов
* Наука о данных (Data Science)
* Интеллектуальный анализ данных (Data Mining)
* Стандартное программирование (Classical Programming)

<p align="center">
  <img src="/intro_to_ml/images/terms.png" width="800">
</p>

### МО, как часть ИИ
<p align="center">
  <img src="/intro_to_ml/images/ml_in_ai.png" width="800">
</p>

### Карта мира МО
<p align="center">
  <img src="/intro_to_ml/images/ml_world_map.png" width="800">
</p>

### Классическое обучение
<p align="center">
  <img src="/intro_to_ml/images/classical_ml.png" width="800">
</p>

### Задачи классического МО
* Обучение с учителем:
    1. **Задача регрессии** - задача предсказания числа по некоторым входным данным
    2. **Задача классификации** - задача отнесения объекта к одному из заранее известных классов
* Обучение без учителя:
    1. **Задача кластеризации** - задача распределения объектов по заранее неизвестным, непересекающимся множествам (кластерам)
    2. **Задача поиска ассоциативных правил** (поиск ассоциаций) - задача выявления закономерностей между связанными элементами (событиями или объектами)
    3. **Задача уменьшения размерности** - это задача нахождения преобразования данных, состоящего в уменьшении числа используемых переменных (возможно новых)

### Обучение с подкреплением
* За каждое действие получает баллы
* Алгоритм Q-learning

### Ансамблевые методы
* Одни из самых точных
* Идея: объединение различных методов
* Разновидности:
    * **Стекинг** - обучает несколько различных алгоритмов и передает их на вход последнему, который принимает финальное решение
    * **Беггинг** - предполагает обучение одного и того же алгоритма много раз на случайных выборках из исходных данных, а в конце усреднение ответов
    * **Бустинг** - предлагает обучать алгоритмы последовательно, причем при каждом следующем обучении новый алгоритм уделяет особое внимание ошибкам предыдущего

### Нейросети и глубокое обучение
* Нейросеть - набор нейронов и связей
* Нейрон - функция с множеством входов и одним единственным выходом
* Связь - канал, через который нейроны передают друг другу числовые значения
    * У каждого канала есть свой вес (пропускная способность, прочность связи)
    * Нейроны связывают по слоям (в реальности это представлено матрицами и вычисляется средставми линйеной алгебры)

## Регрессия

### Модель простейшей линейной регрессии
$$ Y = \theta_0 + \theta_1 X_1 + \epsilon $$

* $\theta_0$ , $\theta_1$ - числовые коэффициенты
* $X1$ - неслучайный параметр, значения задаются или наблюдаются (то есть известны)
* $\epsilon$ - случайная ошибка

### Линия регрессии - функция
$$ f(X_1) = \theta_0 + \theta_1 X_1 $$

### Уравнение регрессии - уравнение
$$ Y = \theta_0 + \theta_1 X_1 $$

### МНК
Метод наименьших квадратов (МНК) - метод поиска коэффициентов регрессии, позволяющий найти такие оценки параметров $\theta_0$ и $\theta_1$, что сумма квадратов ошибок $\epsilon$ в наблюдаемых n экспериментах минимальна.

### Предположения о распределении случайных ошибок
1. Случайные ошибки независимы и одинаково распределены.
2. Ошибки не носят систематического характера (их мат. ожидание равно нулю).
3. Дисперсии ошибок одинаковы.
4. Ошибки подчиняются нормальному распределению с нулевым мат. ожиданием ($\epsilon_i ~ N_{0, \sigma^2}$).

Первые три условия - условия Гаусса-Маркова.

### Доверительный интервал
Доверительный интервал строится на основе **стандартных ошибок (SE)**. На практике часто рассматривают значения $\epsilon = 0.1$, $\epsilon = 0.05$ или $\epsilon = 0.01$.

Доверительный интервал уровня доверия $(1- \epsilon)$ для параметра $\theta_i$ – это интервал:

$$ (\theta_{est_i} - t_{1-\epsilon/2} SE(\theta_{est_i}), \theta_{est_i} + t_{1-\epsilon/2} SE(\theta_{est_i})) $$

* $t_{1-\epsilon/2}$ - квантиль распределения Стьюдента с (n - 2) степенями свободы

### Проверка гипотезы
Для проверки гипотезы также используюся стандартные ошибки (SE).

Обычно проверяют гипотезу статистической значимости параметра $\theta_{est_1}$.

Гипотеза $H_0$: между $X1$ и $Y$ нет зависимости, $H_1$ - есть. 

t-критерий Стьюдента:

$$ t = {|\theta_{est_i}| \over SE(\theta_{est_i})} $$

### Оценка точности модели
1. Среднеквадратическое отклонение остатков (RSE) - оценка среднего квадратического отклонения ($\sigma^2$) ошибки $\epsilon$.
2. $R^2$ статистика - в отличие от RSE, величина безразмерная и лежит между нулем и единицей.

## Классификатор k-NN

### Алгоритм
Алгоритм k-ближайших соседей (k-nearest neighbours)

Проблемы:
* Выбор k
  * Случайное разделение выборки:
    * На две части - тренировочную и тестовую
    
$$ D_{train} : D_{test} = 80 : 20 $$

    * На три части - откалывать от $D_{train}$ validation-part $D_{val}$
  * В случае двухклассовой классификации достаточно брать нечетные k
  * В остальных случаях - взвешанный метод k-NN
    * Каждому объекту тренировочных данных $x_i$ приписывается некоторый вес $\omega_i$, зависящий от тестового объекта z
    * За вес можно взять величину, обратно пропорциональную квадрату расстояния между объекатми $x_i$ и z

$$ \omega_i = \omega_i(x_i, z) = {1 \over d^2(x_i, z)} $$

* Выбор метрики

### Метрики
Метрика (расстояние) - функция, удовлетворяющая трем условиям:
1. Она неотрицательна
2. Она симметричная
3. Выполняется неравенство треугольника

Виды метрик:
1. Евклидова метрика (евклидово расстояние, расстоние по прямой)
  * Обощение теоремы Пифагора
  * Частный случай расстояния Минковского (при q = 2)

$$ d_E(x, x') = \sqrt{\sum_{i=1}^p(x_i - x_i')^2} $$

2. Расстояние Минковского

$$ d_q(x, x') = \sqrt[q]{\sum_{i=1}^p|x_i - x_i'|^q}, q \geq 1 $$

3. Манхэттенское расстояние (расстояние городских кварталов)
  * Частный случай расстояния Минковского (при q = 1)
  * Решает вопрос расчета длины поездки по городу, если все улицы города строго перпендикулярны

$$ d_1(x, x') = \sum_{i=1}^p|x_i - x_i'| $$

4. Расстояние Чебышева
  * Частный случай расстояния Минковского (при $q = \infty$)
  * Показывает максимальное покоординатное отклонение одного объекта от другого

$$ d_{\infty}(x, x') = max|x_i - x_i'|, i \in (1, ...,p) $$

<p align="center">
  <img src="/intro_to_ml/images/metrics.png" width="800">
</p>

### Классификация методом k-NN
1. Вычисляем расстояние от тестового объекта до каждого элемента тренировочного набора данных
2. Упорядочиваем эти расстояния по неубыванию и перенумеровываем элементы тренировочного набора данных (первый элемент – самый близкий к тестовому объекту, второй – второй по близости, и так далее)
3. Перенумеровываем отклики согласно перенумерованным объектам
4. Ищем тот класс (или те классы), объекты которых встретились среди k ближайших элементов чаще всего

Гипотеза компактности - возможные классы образуют компактно локализованные подмножества в пространстве объектов.

Алгоритм k-NN является
* метрическим (анализ сходства объектов с помощью метрики)
* ленивым (обучение просходит лишь в момент предсказания)

### Нормализация данных
Разные единицы измерения признаковмогут искажать расстояние между объектами.

Линейная нормировка:

$$ X_i' = {X_i - X_{min} \over X_{max} - X_{min}} $$

* $X_{min}$ – минимальное значение рассматриваемого предиктора
* $X_{max}$ – максимальное значение
* $X_i$ – нормируемое значение
* $X_i′$ – нормированное значение

### Оценка алгоритма
Алгоритм – это функция, сопоставляющая произвольному объекту некоторый отклик.

Функция потерь: $L(a, x)$
* $a$ - алгоритм
* $x$ - объект

Если $L(a, x) = 0$, то ответ $a(x)$ - корректный.

Эмпирический риск (функционал средних потерь) - доля неправильных построенного классификатора на наборе данных:

$$ Q(a, l, x_1, ..., x_n) = {1 \over n} \sum_{i=1}^nL(a, x_i) = {1 \over n} \sum_{i=1}^nI(a(x_i) \not= y(x_i)) $$

Алгоритм тем лучше, чем меньше значение соответствующего ему функционала потерь.

### Разделение набора данных
Чтобы модель не **переобучалась**, исходный набор данных принято случайно разделять:
* На две части - тренировочную и тестовую

$$ D_{train} : D_{test} = 80 : 20 $$

* На три части - откалывать от $D_{train}$ validation-part $D_{val}$)
  * Имея набор данных $D_{val}$, имеет смысл выбрать тот алгоритм, который допускает меньшее число ошибок на этом наборе данных, и тогда именно этот алгоритм и нужно оценить на $D_{test}$, предварительно обучив на всем наборе $D_{train}$ (включая искуственно отколотый набор $D_{val}$)

### k-блочная кросс-валидация
<p align="center">
  <img src="/intro_to_ml/images/cross_validation.png" width="800">
</p>

По сути дела тренировочный набор данных $D_{train}$ делится на несколько более маленьких кусочков, каждый из которых на своей итерации выступает тестовым набором данных – набором данных для оценивания алгоритма. Финальная оценка каждого алгоритма – это усреднение оценок на каждой итерации.

## Наивный байесовский классификатор

### Метрические vs Вероятностные модели
Наивный байесовский классификатор - **вероятностный** классификатор, в основе которого лежит теорема Байеса.

Данные могут быть **неточными** и **неполными**, поэтому предположение о существовании явной зависимости, дающей по описанию объекта единственно верный ответ (отклик), кажется достаточно наивным.

Вероятностные модели позволяют, в некотором смысле, устранить описанную некорректность.

### Формулы
Формула умножения вероятностей:

$$ P(AB) = P(A)P(B/A) = P(B)P(A/B) $$

Tеорема Байеса превращает результаты испытаний в вероятность событий:

$$ P(A/B) = {P(A)P(B/A) \over P(B)} $$

* $P(A)$ - априорная вероятность гипотезы A
* $P(A/B)$ - вероятность гипотезы A при наступлении события B (апостериорная вероятность)
* $P(B/A)$ - вероятность наступления события B при истинности гипотезы A (правдоподобие)
* $P(B)$ - априорная вероятность наступления события B 

Замечание: истинные вероятности неизвестны, но их можно оценить, используя **частоту**.

### Почему наивный?
На практике совместное распределение $P(X_1, X_2, ..., X_p | Класс = y)$ не известно, поэтому классификатор работает в предположении **условной независимости предикторов** при условии данной метки класса.

$$ P(X_1, X_2, ..., X_p | Класс = y) = P(X_1 | Класс = y) P(X_2 | Класс = y) ... P(X_p | Класс = y)$$

### Перемножение малых величин
В случае, если объем тренировочных данных велик, а вероятности (или их оценки) малы, то результат перемножения компьютерными средствами, имеющими ограниченную точность, приведет к чему-то вроде
нуля. Для решения этой проблемы переходят к **натуральному логарифму**.

Для двоичного классификатора с двумя предикторами формула вероятности отнесения к классу y*:

$$ P(Класс = y^* | X_1, X_2) = {1 \over 1 + e^{F(y) - F(y^*)}} $$

$$ F(y) = ln{P(Класс = y)} + \sum_{i = 1}^2{ln{P(X_i|Класс = y)}} $$

### Неизвестное число значений предиктора
На примере спам-фильтра **сглаживание по Лапласу** – предположить, что мы видели каждое слово **на один раз больше**.

$$ P(X | Класс = y) = {количество слов X в классе y \over количество слов в классе y} $$

$$ P(X | Класс = y) = {1 + количество слов X в классе y \over |V| + количество слов в классе y} $$

* $|V|$ - количество слов в словаре

А что, если в письме встретилось слово, которого **нет в словаре**? Есть два варианта: либо это слово можно выкинуть из рассмотрения, то есть пропустить, либо в момент классификации **переучить** построенный классификатор, используя снова сглаживание по Лапласу.

$$ P(X | Класс = y) = {1 + количество слов X в классе y \over |V| + r + количество слов в классе y} $$

* $r$ - количество слов в письме, которых нет в словаре
