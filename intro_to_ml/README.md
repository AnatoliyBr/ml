## 2. Введение в МО (Python)

## Содержание
* [Введение в машинное обучение](#введение-в-машинное-обучение)
* [Регрессия](#регрессия)
* Задача классификации
    * [k-NN](#классификатор-k-nn)
    * Наивный байесовский классификатор
    * Логистическая регрессия
* Кластеризация

## Введение в машинное обучение

### Определения
* Машинное обучение (МО) - статистическое обучение
* Предикторы (признаки) - входные данные (независимые переменные)
* Отклики - выходные данные (зависимые переменные)
* Тренировочный набор данных - для обучения модели
* Тестовый набор данных - для проверки эффективности ("правильности") модели

### Диаграмма терминов
* Наука о данных (Data Science)
* Интеллектуальный анализ данных (Data Mining)
* Стандартное программирование (Classical Programming)

<p align="center">
  <img src="/intro_to_ml/images/terms.png" width="800">
</p>

### МО, как часть ИИ
<p align="center">
  <img src="/intro_to_ml/images/ml_in_ai.png" width="800">
</p>

### Карта мира МО
<p align="center">
  <img src="/intro_to_ml/images/ml_world_map.png" width="800">
</p>

### Классическое обучение
<p align="center">
  <img src="/intro_to_ml/images/classical_ml.png" width="800">
</p>

### Задачи классического МО
* Обучение с учителем:
    1. **Задача регрессии** - задача предсказания числа по некоторым входным данным
    2. **Задача классификации** - задача отнесения объекта к одному из заранее известных классов
* Обучение без учителя:
    1. **Задача кластеризации** - задача распределения объектов по заранее неизвестным, непересекающимся множествам (кластерам)
    2. **Задача поиска ассоциативных правил** (поиск ассоциаций) - задача выявления закономерностей между связанными элементами (событиями или объектами)
    3. **Задача уменьшения размерности** - это задача нахождения преобразования данных, состоящего в уменьшении числа используемых переменных (возможно новых)

### Обучение с подкреплением
* За каждое действие получает баллы
* Алгоритм Q-learning

### Ансамблевые методы
* Одни из самых точных
* Идея: объединение различных методов
* Разновидности:
    * **Стекинг** - обучает несколько различных алгоритмов и передает их на вход последнему, который принимает финальное решение
    * **Беггинг** - предполагает обучение одного и того же алгоритма много раз на случайных выборках из исходных данных, а в конце усреднение ответов
    * **Бустинг** - предлагает обучать алгоритмы последовательно, причем при каждом следующем обучении новый алгоритм уделяет особое внимание ошибкам предыдущего

### Нейросети и глубокое обучение
* Нейросеть - набор нейронов и связей
* Нейрон - функция с множеством входов и одним единственным выходом
* Связь - канал, через который нейроны передают друг другу числовые значения
    * У каждого канала есть свой вес (пропускная способность, прочность связи)
    * Нейроны связывают по слоям (в реальности это представлено матрицами и вычисляется средставми линйеной алгебры)

## Регрессия

### Модель простейшей линейной регрессии
$$ Y = \theta_0 + \theta_1 X_1 + \epsilon $$

* $\theta_0$ , $\theta_1$ - числовые коэффициенты
* $X1$ - неслучайный параметр, значения задаются или наблюдаются (то есть известны)
* $\epsilon$ - случайная ошибка

### Линия регрессии - функция
$$ f(X_1) = \theta_0 + \theta_1 X_1 $$

### Уравнение регрессии - уравнение
$$ Y = \theta_0 + \theta_1 X_1 $$

### МНК
Метод наименьших квадратов (МНК) - метод поиска коэффициентов регрессии, позволяющий найти такие оценки параметров $\theta_0$ и $\theta_1$, что сумма квадратов ошибок $\epsilon$ в наблюдаемых n экспериментах минимальна.

### Предположения о распределении случайных ошибок
1. Случайные ошибки независимы и одинаково распределены.
2. Ошибки не носят систематического характера (их мат. ожидание равно нулю).
3. Дисперсии ошибок одинаковы.
4. Ошибки подчиняются нормальному распределению с нулевым мат. ожиданием ($\epsilon_i ~ N_{0, \sigma^2}$).

Первые три условия - условия Гаусса-Маркова.

### Доверительный интервал
Доверительный интервал строится на основе **стандартных ошибок (SE)**. На практике часто рассматривают значения $\epsilon = 0.1$, $\epsilon = 0.05$ или $\epsilon = 0.01$.

Доверительный интервал уровня доверия $(1- \epsilon)$ для параметра $\theta_i$ – это интервал:

$$ (\theta_{est_i} - t_{1-\epsilon/2} SE(\theta_{est_i}), \theta_{est_i} + t_{1-\epsilon/2} SE(\theta_{est_i})) $$

* $t_{1-\epsilon/2}$ - квантиль распределения Стьюдента с (n - 2) степенями свободы

### Проверка гипотезы
Для проверки гипотезы также используюся стандартные ошибки (SE).

Обычно проверяют гипотезу статистической значимости параметра $\theta_{est_1}$.

Гипотеза $H_0$: между $X1$ и $Y$ нет зависимости, $H_1$ - есть. 

t-критерий Стьюдента:

$$ t = {|\theta_{est_i}| \over SE(\theta_{est_i})} $$

### Оценка точности модели
1. Среднеквадратическое отклонение остатков (RSE) - оценка среднего квадратического отклонения ($\sigma^2$) ошибки $\epsilon$.
2. $R^2$ статистика - в отличие от RSE, величина безразмерная и лежит между нулем и единицей.

## Классификатор k-NN

### Алгоритм
Алгоритм k-ближайших соседей (k-nearest neighbours)

Проблемы:
* Выбор k
  * Случайное разделение выборки:
    * На две части - тренировочную и тестовую
        * $$ D_{train} : D_{test} = 80 : 20 $$
    * На три части - откалывать от $D_{train}$ validation-part $D_{val}$
  * В случае двухклассовой классификации достаточно брать нечетные k
  * В остальных случаях - взвешанный метод k-NN
    * Каждому объекту тренировочных данных $x_i$ приписывается некоторый вес $\omega_i$, зависящий от тестового объекта z
    * За вес можно взять величину, обратно пропорциональную квадрату расстояния между объекатми $x_i$ и z
      * $$ \omega_i = \omega_i(x_i, z) = {1 \over d^2(x_i, z)} $$
* Выбор метрики

### Метрики
Метрика (расстояние) - функция, удовлетворяющая трем условиям:
1. Она неотрицательна
2. Она симметричная
3. Выполняется неравенство треугольника

Виды метрик:
1. Евклидова метрика (евклидово расстояние, расстоние по прямой) - обощение теоремы Пифагора
  * $$ d_E(x, x') = \sqrt{\sum_{i=1}^p(x_i - x_i')^2} $$
  * Частный случай расстояния Минковского (при q = 2)
2. Расстояние Минковского
  * $$ d_q(x, x') = \sqrt[q]{\sum_{i=1}^p|x_i - x_i'|^q}, q \geq 1 $$
3. Манхэттенское расстояние (расстояние городских кварталов)
  * $$ d_1(x, x') = \sum_{i=1}^p|x_i - x_i'| $$
  * Частный случай расстояния Минковского (при q = 1)
  * Решает вопрос расчета длины поездки по городу, если все улицы города строго перпендикулярны
4. Расстояние Чебышева
  * $$ d_{\infty}(x, x') = max|x_i - x_i'|, i \in (1, ...,p) $$
  * Частный случай расстояния Минковского (при $q = \infty$)
  * Показывает максимальное покоординатное отклонение одного объекта от другого

<p align="center">
  <img src="/intro_to_ml/images/metrics.png" width="800">
</p>

### Классификация методом k-NN
1. Вычисляем расстояние от тестового объекта до каждого элемента тренировочного набора данных
2. Упорядочиваем эти расстояния по неубыванию и перенумеровываем элементы тренировочного набора данных (первый элемент – самый близкий к тестовому объекту, второй – второй по близости, и так далее)
3. Перенумеровываем отклики согласно перенумерованным объектам
4. Ищем тот класс (или те классы), объекты которых встретились среди k ближайших элементов чаще всего

Гипотеза компактности - возможные классы образуют компактно локализованные подмножества в пространстве объектов.

Алгоритм k-NN является
* метрическим (анализ сходства объектов с помощью метрики)
* ленивым (обучение просходит лишь в момент предсказания)

### Нормализация данных
Разные единицы измерения признаковмогут искажать расстояние между объектами.

Линейная нормировка:

$$ X_i' = {X_i - X_{min} \over X_{max} - X_{min}} $$

* $X_{min}$ – минимальное значение рассматриваемого предиктора
* $X_{max}$ – максимальное значение
* $X_i$ – нормируемое значение
* $X_i′$ – нормированное значение

### Оценка алгоритма
Алгоритм – это функция, сопоставляющая произвольному объекту некоторый отклик.

Функция потерь: $L(a, x)$
* $a$ - алгоритм
* $x$ - объект

Если $L(a, x) = 0$, то ответ $a(x)$ - корректный.

Эмпирический риск (функционал средних потерь) - доля неправильных построенного классификатора на наборе данных:

$$ Q(a, l, x_1, ..., x_n) = {1 \over n} \sum_{i=1}^nL(a, x_i) = {1 \over n} \sum_{i=1}^nI(a(x_i) \not= y(x_i)) $$

Алгоритм тем лучше, чем меньше значение соответствующего ему функционала потерь.

### Разделение набора данных
Чтобы модель не **переобучалась**, исходный набор данных принято случайно разделять:
* На две части - тренировочную и тестовую
    * $$ D_{train} : D_{test} = 80 : 20 $$
* На три части - откалывать от $D_{train}$ validation-part $D_{val}$)
  * Имея набор данных $D_{val}$, имеет смысл выбрать тот алгоритм, который допускает меньшее число ошибок на этом наборе данных, и тогда именно этот алгоритм и нужно оценить на $D_{test}$, предварительно обучив на всем наборе $D_{train}$ (включая искуственно отколотый набор $D_{val}$)

### k-блочная кросс-валидация
<p align="center">
  <img src="/intro_to_ml/images/cross_validation.png" width="800">
</p>

По сути дела тренировочный набор данных $D_{train}$ делится на несколько более маленьких кусочков, каждый из которых на своей итерации выступает тестовым набором данных – набором данных для оценивания алгоритма. Финальная оценка каждого алгоритма – это усреднение оценок на каждой итерации.

## Наивный байесовский классификатор